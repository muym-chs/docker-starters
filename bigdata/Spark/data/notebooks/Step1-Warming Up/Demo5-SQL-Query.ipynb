{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1770c85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55e4c9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/10/06 09:09:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .appName(\"Step1_5-SQL-Query\") \\\n",
    "    .config(\"spark.executor.memory\", \"500mb\") \\\n",
    "    .config(\"spark.executor.cores\",\"1\") \\\n",
    "    .config(\"spark.cores.max\", \"1\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f62b9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.setLogLevel(\"ERROR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98907184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1.4M\r\n",
      "-rwxrwxrwx 1 root root 1.5K Sep 20 18:13 sample.csv\r\n",
      "-rwxrwxrwx 1 root root  68K May 15  2018 xad.csv\r\n",
      "-rwxrwxrwx 1 root root  68K May 15  2018 xae.csv\r\n",
      "-rwxrwxrwx 1 root root  69K May 15  2018 xag.csv\r\n",
      "-rwxrwxrwx 1 root root  68K May 15  2018 xah.csv\r\n",
      "-rwxrwxrwx 1 root root  68K May 15  2018 xai.csv\r\n",
      "-rwxrwxrwx 1 root root  68K May 15  2018 xaj.csv\r\n",
      "-rwxrwxrwx 1 root root  68K May 15  2018 xak.csv\r\n",
      "-rwxrwxrwx 1 root root  68K May 15  2018 xam.csv\r\n",
      "-rwxrwxrwx 1 root root  68K May 15  2018 xao.csv\r\n",
      "-rwxrwxrwx 1 root root  68K May 15  2018 xap.csv\r\n",
      "-rwxrwxrwx 1 root root  68K May 15  2018 xaq.csv\r\n",
      "-rwxrwxrwx 1 root root  68K May 15  2018 xar.csv\r\n",
      "-rwxrwxrwx 1 root root  68K May 15  2018 xas.csv\r\n",
      "-rwxrwxrwx 1 root root  68K May 15  2018 xat.csv\r\n",
      "-rwxrwxrwx 1 root root  68K May 15  2018 xau.csv\r\n",
      "-rwxrwxrwx 1 root root  67K May 15  2018 xav.csv\r\n",
      "-rwxrwxrwx 1 root root  68K May 15  2018 xax.csv\r\n",
      "-rwxr-xr-x 1 root root  69K Oct  6 05:50 xay.csv\r\n",
      "-rwxrwxrwx 1 root root  68K May 15  2018 xaz.csv\r\n",
      "-rwxrwxrwx 1 root root  68K May 15  2018 xbb.csv\r\n"
     ]
    }
   ],
   "source": [
    "! ls -lh /opt/spark-data/datasets/droplocation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90f05896",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([StructField(\"lsoa_code\", StringType(), True),\\\n",
    "                         StructField(\"borough\", StringType(), True),\\\n",
    "                         StructField(\"major_category\", StringType(), True),\\\n",
    "                         StructField(\"minor_category\", StringType(), True),\\\n",
    "                         StructField(\"value\", StringType(), True),\\\n",
    "                         StructField(\"year\", StringType(), True),\\\n",
    "                         StructField(\"month\", StringType(), True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52059ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileStreamDF = spark.readStream\\\n",
    "                               .option(\"header\", \"true\")\\\n",
    "                               .schema(schema)\\\n",
    "                               .option(\"maxFilesPerTrigger\", 1)\\\n",
    "                               .csv(\"/opt/spark-data/datasets/droplocation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72cf5a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registering Table\n",
    "# Create a view which can later be queried like a table\n",
    "fileStreamDF.createOrReplaceTempView(\"LondonCrimeData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d61e476",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoryDF = spark.sql(\"SELECT major_category, value \\\n",
    "                                    FROM LondonCrimeData \\\n",
    "                                    WHERE year = '2016'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba135a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use groupBy and agg functions to get total convictions per major_category\n",
    "# The new column created will be called sum(value) - rename to something meaningful\n",
    "# Order by number of convictions in descending order\n",
    "convictionsPerCategory = categoryDF.groupBy(\"major_category\")\\\n",
    "                                      .agg({\"value\": \"sum\"})\\\n",
    "                                      .withColumnRenamed(\"sum(value)\", \"convictions\")\\\n",
    "                                      .orderBy(\"convictions\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cab5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+---------------------------+-----------+\n",
      "|major_category             |convictions|\n",
      "+---------------------------+-----------+\n",
      "|Violence Against the Person|1.0        |\n",
      "|Theft and Handling         |0.0        |\n",
      "+---------------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Write out our dataframe to the console\n",
    "query = convictionsPerCategory.writeStream\\\n",
    "                      .outputMode(\"complete\")\\\n",
    "                      .format(\"console\")\\\n",
    "                      .option(\"truncate\", \"false\")\\\n",
    "                      .option(\"numRows\", 30)\\\n",
    "                      .start()\\\n",
    "                      .awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e058c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit App :\n",
    "# Submit codes/demo2.py \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f09f943",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
